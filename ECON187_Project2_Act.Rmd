---
title: "ECON 187 Project 2"
author: "Arif Abd Aziz, Jon Girolamo, Shanie Talor"
date: "2023-05-18"
output: pdf_document
---

#Notes
#pull 
#add/save
#commit 
#pull(to get someone elses)/push (to give yours to everyone else) 

# Brief Introduction to Part I:

The data we found explores the relationship between the fat content of multiple different food items against the incidence and prevalence of COVID 19. The data is aggregated from 170 countries (170 observations), and we plan to use a variety of non-linear techniques to create a model that predicts COVID contraction rates from aggregated nutrition variables (pertaining to food fat content). 

# Read & Clean Covid Data:
```{r}
# Clear Environment:
rm(list = ls())

# Read Data into Environment
nutrition <- read.csv("Fat_Supply_Quantity_Data.csv", sep = ",",
                      header = TRUE)
head(nutrition)

# See Variable Names
names(nutrition)

# Distribution/Histogram of Quantitative Variables: Broken into 3 Parts
# First nine variables
par(mfrow = c(3,3)) # Break this up because need plots to look clean
for (variable in names(nutrition)[1:9]) {
  if (is.numeric(nutrition[[variable]])) {
    hist(nutrition[[variable]], main = variable, xlab = paste0(variable," values"))
  }
}

# Second group of nine variables
par(mfrow = c(3,3))
for (variable in names(nutrition)[10:18]) {
  if (is.numeric(nutrition[[variable]])) {
    hist(nutrition[[variable]], main = variable, xlab = paste0(variable," values"))
  }
}

# Last Group of Nine Variables
par(mfrow = c(3,3))
for (variable in names(nutrition)[19:27]) {
  if (is.numeric(nutrition[[variable]])) {
    hist(nutrition[[variable]], main = variable, xlab = paste0(variable," values"))
  }
}

# Last Group of 5 Variables
par(mfrow = c(3,2))
for (variable in names(nutrition)[28:32]) {
  if (is.numeric(nutrition[[variable]])) {
    hist(nutrition[[variable]], main = variable, xlab = paste0(variable," values"))
  }
}
```

There are a lot of predictors in this data set, representing the fat contents of various foods. We want to model for variables that show a high degree of variation. We can pick out these predictors from their histograms. Those that are concentrated at certain values may not give us the insights into predicting the incidence of COVID-19 in different countries. For example, aquatic products and their fat contents don't exhibit strong variation. This makes sense since some countries may not have aquatic products. Though this variable may help to predict COVID 19 incidence in countries that do consume aquatic products, it may pick up dynamics in non-aquatic consuming countries that do not exist in the data. 

We also want to remove variables that may contain similar information to others, such as "Sugar Crops" and "Sugar Sweetners". Our main response variables are COVID-19 deaths and confirmed cases. These represent proportions of a country's total population.  

```{r}
# Keep Variables That We'd Like to Study 
library(dplyr)
nutrition <- nutrition %>% select(-c("Country", "Alcoholic.Beverages",
                                     "Aquatic.Products..Other", "Oilcrops",
                                     "Sugar.Crops", "Population",
                                     "Unit..all.except.Population.", "Recovered",
                                     "Active"))

# Remove Empty NA Values, Assuming Death Rate is Our Main Response Variable
removena <- which(is.na(nutrition$Deaths))
nutrition <- nutrition[-removena,]
nrow(nutrition)

# Check to See if Any Other NA Values in Main Variables:
for (variable in names(nutrition)){
  print(paste0(variable," has NA values: ",any(is.na(nutrition[[variable]]))))
} # See That Obesity and Undernourished Variables Still Have NA Values

removena_obesity <- which(is.na(nutrition$Obesity))
removena_undernourished <- which(is.na(nutrition$Undernourished))

# Remove Further NA Values
nutrition <- nutrition[-removena_obesity,]
nutrition <- nutrition[-c(5,11,59,120,124,125,137,144),]
nrow(nutrition)
nutrition <- na.omit(nutrition)
nrow(nutrition) 
```

Now that our data set is largely cleaned, removing for predictors we are not interested in and adjusting for empty values, we can now look into feature selection methods. The main one we will use is the Boruta algorithm which uses random forests to pick out a subset of best predictors. We will assume that Covid-19 deaths is our response variable. 

# Feature Selection
```{r, echo = FALSE}
# Boruta Algorithm
library(Boruta)
library(randomForest)
boruta_covid <- Boruta(Deaths~.-Confirmed, data = nutrition, doTrace = 2, 
                       randomForest = TRUE)
```

```{r}
# Boruta Plot
plot(boruta_covid, main = "Boruta Algorithm Feature Selection", las = 2)
```

According to our Boruta plot, ten out of the twenty three predictors we shortlisted are significant in explaining and predicting COVID-19 deaths. Moving forward, we'll be using these 10 predictors and applying specific transformations of them (splines, polynomials) to predict COVID-19 deaths. 

Here are the best predictors according to Boruta: "Stimulants", "Pulses", "Vegetable.Oils", "Miscellaneous", "Undernourished", "Milk...Excluding.Butter", "Fish..Seafood", "Vegetal.Products", "Animal.Products", "Animal.fats", "Eggs", "Obesity".

# Relationship Between Response Variable & Chosen Predictors
```{r}
# Keep Variables We Want to Model
nutrition_cln <- nutrition %>% select(-c("Fruits...Excluding.Wine","Spices",
                                         "Sugar...Sweeteners","Vegetables",
                                         "Offals","Treenuts","Meat",
                                         "Starchy.Roots", "Confirmed"))

# Convert Undernourished into Numerical Variable
nutrition_cln$Undernourished[nutrition_cln$Undernourished == "<2.5"] <- 2.5
nutrition_cln$Undernourished <- as.numeric(nutrition_cln$Undernourished) # make numeric

# Create For Function to See Plots of All Predictors Against Covid 19 Deaths
for (variable in names(nutrition_cln)){
  plot(nutrition_cln[[variable]], nutrition_cln$Deaths, main = paste0("COVID 19 Deaths Against ",variable), xlab = variable, ylab = "Population Proportion of Deaths")
}
```

# Creating folds for all Cross-Validation Testing
```{r}
library(caret)
set.seed(123)
folds <- createFolds(nutrition$Deaths, k = 5, returnTrain = TRUE)
```

# Piecewise Polynomial: Shanie (Leave Descriptions Until Last, Just Write Code)
```{r}

```


# Splines: Arif (Leave Descriptions Until Last, Just Write Code)

Since we have many predictors to account for, I'll be optimizing each predictor against our response variable (COVID-19 deaths) individually and separately. In order to fit splines to our data, We'll be using a matrix of spline functions, or basis functions (bs()). Though we could individually set knots for each variable and test its general performance, we do not have a strong understanding of nutritional theory. Thus, instead, we'll use cross-validation techniques to optimize the degrees of freedom for each predictor and their corresponding basis functions. The degrees of freedom take into account the best knots for the predictors. Instead of mixing and matching different predictors and their basis functions, we'll be working on each predictor's basis functions individually, then compiling the best based on cross-validation performance. 

```{r}
# Cross Validation for Each Variable Using Splines and Basis Functions 
library(splines)
variable_list <- list() # Empty List to Store Performance Scores for Each Predictor

### Animal Products Test ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Animal.Products, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Animal.Products Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Animal.Products"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means))

### Animal Fats Test ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Animal.fats, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Animal.fats Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Animal.fats"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means))

### Cereals Excluding Beer ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Cereals...Excluding.Beer, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Cereals...Excluding.Beer Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Cereals...Excluding.Beer"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means))

### Eggs ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Eggs, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Eggs Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Eggs"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means))

### Fish Seafood ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Fish..Seafood, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Fish..Seafood Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Fish..Seafood"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means))

### Miscellaneous ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Miscellaneous, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Miscellaneous Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Miscellaneous"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means))

### Milk...Excluding.Butter Seafood ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Milk...Excluding.Butter, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Milk...Excluding.Butter Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Milk...Excluding.Butter"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means)) 

### Pulses ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Pulses, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Pulses Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Pulses"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means)) 

### Stimulants ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Stimulants, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Stimulants Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Stimulants"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means)) 

### Vegetal.Products ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Vegetal.Products, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Vegetal.Products Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Vegetal.Products"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means)) 

### Vegetable.Oils ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Vegetable.Oils, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Vegetable.Oils Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Vegetable.Oils"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means)) 

### Obesity ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Obesity, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Obesity Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Obesity"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means)) 

### Undernourished ###
cv_num_vector <- 4:15 # First Column of Data to Represent Degrees of Freedom
cv_error_df <- data.frame(cv_num_vector) # Put Column into Data Frame
emptyvector <- vector() # Vector for Mean Squared Error Scores

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  for (j in 4:15){
    fit <- lm(Deaths ~ ns(Undernourished, df = j), data = nutrition_cln, 
              subset = train_index) # Fit Natural Spline (Cubic) Varying DFs
    prediction <- predict(fit, newdata = nutrition_test) # Predict on Test Set
    mse_score <- mean((nutrition_test$Deaths-prediction)^2) # MSE Calculation
    emptyvector[j-3] <- round(mse_score,6)
  }
  cv_error_df <- cbind(cv_error_df,emptyvector) # Add MSE from DF into Data Frame
  emptyvector <- vector() # Empty Vector
}

# Clean Data Frame & Return Values to Main Data Frame
colnames(cv_error_df) <- c("Degrees of Freedom","Fold 1", "Fold 2", "Fold 3", 
                           "Fold 4", "Fold 5")
cv_error_df$Means <- round(rowMeans(cv_error_df[,2:6]),6)
print(cv_error_df)
print(paste0("Minimum Degree of Freedom for Undernourished Natural Spline: ",
             cv_error_df[which.min(cv_error_df$Means),1])) 
variable_list[["Undernourished"]] <- c(cv_error_df[which.min(cv_error_df$Means),1],
                             min(cv_error_df$Means)) 

### Print Full Variable List ####
print(variable_list) # Natural Splines Fit for Individual Variables
```

Looking at our full list of variables and their natural spline performance, we see that the natural splines that returned the lowest MSE scores were: Obesity, Undernourished, Eggs, Animal Products, Vegetal Products, and Animal Fats. All of these natural splines produced an MSE score of below 0.002. Moreover, we ran for loops that tested degrees of freedom between 4 and 15 and surprisingly most of our optimal degrees of freedom for each individual variable are below 6. This in theory reduces potential overfitting in testing sets. Moving forward, we will consider potential combinations of these splines, emphasizing the variables that performed the best in our (natural spline) cross validation exercise. In order to figure out which combinations of variables are optimal, we'll be using a cross-validation approach using the same folds set before. We'll be comparing MSE and AIC/BIC scores. Though there may be more robust algorithms that can optimize a variety of combinations of variables, we'll be using an approach similar to forward step-wise selection. In this version, we'll be adding the best natural spline variables in order of their MSE performance from the previous section. 

Order: Obesity, Eggs, Undernourished, Animal Products, Vegetal Products, Animal Fats

```{r}
###### Assess & Try Different Combinations of Natural Splines #####
mse_vector_ns <- vector()
bic_vector_ns <- vector()
model_comp_df <- data.frame()

# Model 1 Natural Splines: Obesity Only
for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  
  # Model Fit & Predict on Testing Data
  model <- lm(Deaths ~ ns(Obesity,4), data = nutrition_cln, subset = train_index)
  predictions <- predict(model, newdata = nutrition_test) 
  
  # MSE Calculation & Input into Vector
  mse_score <- mean((nutrition_test$Deaths-predictions)^2) 
  mse_vector_ns[i] <- mse_score
  
  # BIC Calculation
  n <- nrow(nutrition_test) # For AIC/BIC Calculations
  p <- length(model$coefficients) # Number of Parameters, Will Change Between Models
  bic_vector_ns[i] <- (n*log(mse_score))+(p*log(n))
}

model1 <- c(mean(mse_vector_ns),mean(bic_vector_ns)) 
model_comp_df <- data.frame(model1)
rownames(model_comp_df) <- c("MSE", "BIC")  

# Model 2 Natural Splines: Obesity, Eggs

mse_vector_ns <- vector() # Reset Vectors
bic_vector_ns <- vector()

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  
  # Model Fit & Predict on Testing Data
  model <- lm(Deaths ~ ns(Obesity,4)+ns(Eggs,4), data = nutrition_cln, 
              subset = train_index)
  predictions <- predict(model, newdata = nutrition_test) 
  
  # MSE Calculation & Input into Vector
  mse_score <- mean((nutrition_test$Deaths-predictions)^2) 
  mse_vector_ns[i] <- mse_score
  
  # BIC Calculation
  n <- nrow(nutrition_test) # For AIC/BIC Calculations
  p <- length(model$coefficients) # Number of Parameters, Will Change Between Models
  bic_vector_ns[i] <- (n*log(mse_score))+(p*log(n))
}

model2 <- c(mean(mse_vector_ns),mean(bic_vector_ns)) 
model_comp_df <- cbind(model_comp_df, model2)

# Model 3 Natural Splines: Obesity, Eggs, Undernourished

mse_vector_ns <- vector() # Reset Vectors
bic_vector_ns <- vector()

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  
  # Model Fit & Predict on Testing Data
  model <- lm(Deaths ~ ns(Obesity,4)+ns(Eggs,4)+ns(Undernourished,4), 
              data = nutrition_cln, subset = train_index)
  predictions <- predict(model, newdata = nutrition_test) 
  
  # MSE Calculation & Input into Vector
  mse_score <- mean((nutrition_test$Deaths-predictions)^2) 
  mse_vector_ns[i] <- mse_score
  
  # BIC Calculation
  n <- nrow(nutrition_test) # For AIC/BIC Calculations
  p <- length(model$coefficients) # Number of Parameters, Will Change Between Models
  bic_vector_ns[i] <- (n*log(mse_score))+(p*log(n))
}

model3 <- c(mean(mse_vector_ns),mean(bic_vector_ns)) 
model_comp_df <- cbind(model_comp_df, model3)

# Model 4 Natural Splines: Obesity, Eggs, Undernourished, Animal Products

mse_vector_ns <- vector() # Reset Vectors
bic_vector_ns <- vector()

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  
  # Model Fit & Predict on Testing Data
  model <- lm(Deaths ~ ns(Obesity,4)+ns(Eggs,4)+ns(Undernourished,4)+
                ns(Animal.Products,5)+ns(), data = nutrition_cln, subset = train_index)
  predictions <- predict(model, newdata = nutrition_test) 
  
  # MSE Calculation & Input into Vector
  mse_score <- mean((nutrition_test$Deaths-predictions)^2) 
  mse_vector_ns[i] <- mse_score
  
  # BIC Calculation
  n <- nrow(nutrition_test) # For AIC/BIC Calculations
  p <- length(model$coefficients) # Number of Parameters, Will Change Between Models
  bic_vector_ns[i] <- (n*log(mse_score))+(p*log(n))
}

model4 <- c(mean(mse_vector_ns),mean(bic_vector_ns)) 
model_comp_df <- cbind(model_comp_df, model4)

# Model 5 Natural Splines: Obesity, Eggs, Undernourished, Ani Prod, Veg Products

mse_vector_ns <- vector() # Reset Vectors
bic_vector_ns <- vector()

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  
  # Model Fit & Predict on Testing Data
  model <- lm(Deaths ~ ns(Obesity,4)+ns(Eggs,4)+ns(Undernourished,4)+
                ns(Animal.Products,5)+ns(Vegetal.Products,5), 
              data = nutrition_cln, subset = train_index)
  predictions <- predict(model, newdata = nutrition_test) 
  
  # MSE Calculation & Input into Vector
  mse_score <- mean((nutrition_test$Deaths-predictions)^2) 
  mse_vector_ns[i] <- mse_score
  
  # BIC Calculation
  n <- nrow(nutrition_test) # For AIC/BIC Calculations
  p <- length(model$coefficients) # Number of Parameters, Will Change Between Models
  bic_vector_ns[i] <- (n*log(mse_score))+(p*log(n))
}

model5 <- c(mean(mse_vector_ns),mean(bic_vector_ns)) 
model_comp_df <- cbind(model_comp_df, model5)

# Model 6 Natural Splines: Obesity, Eggs, Under, Ani Prod, Veg Products, Ani Fat

mse_vector_ns <- vector() # Reset Vectors
bic_vector_ns <- vector()

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  
  # Model Fit & Predict on Testing Data
  model <- lm(Deaths ~ ns(Obesity,4)+ns(Eggs,4)+ns(Undernourished,4)+
                ns(Animal.Products,5)+ns(Vegetal.Products,5)+
                ns(Animal.fats,4), data = nutrition_cln, subset = train_index)
  predictions <- predict(model, newdata = nutrition_test) 
  
  # MSE Calculation & Input into Vector
  mse_score <- mean((nutrition_test$Deaths-predictions)^2) 
  mse_vector_ns[i] <- mse_score
  
  # BIC Calculation
  n <- nrow(nutrition_test) # For AIC/BIC Calculations
  p <- length(model$coefficients) # Number of Parameters, Will Change Between Models
  bic_vector_ns[i] <- (n*log(mse_score))+(p*log(n))
}

model6 <- c(mean(mse_vector_ns),mean(bic_vector_ns)) 
model_comp_df <- cbind(model_comp_df, model6) 

# Sanity Check Model Natural Splines: Obesity, Animal Products

mse_vector_ns <- vector() # Reset Vectors
bic_vector_ns <- vector()

for (i in 1:length(folds)){
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  nutrition_test <- nutrition_cln[test_index,]
  
  # Model Fit & Predict on Testing Data
  model <- lm(Deaths ~ ns(Obesity,4)+ns(Animal.Products,5), 
              data = nutrition_cln, subset = train_index)
  predictions <- predict(model, newdata = nutrition_test) 
  
  # MSE Calculation & Input into Vector
  mse_score <- mean((nutrition_test$Deaths-predictions)^2) 
  mse_vector_ns[i] <- mse_score
  
  # BIC Calculation
  n <- nrow(nutrition_test) # For AIC/BIC Calculations
  p <- length(model$coefficients) # Number of Parameters, Will Change Between Models
  bic_vector_ns[i] <- (n*log(mse_score))+(p*log(n))
}

mean(mse_vector_ns)
mean(bic_vector_ns) #See That These Values Are Not As Optimal As Comparable Mdl2

# Analyze Full Natural Spline Fit Models:
print(model_comp_df)
```

Taking into account MSE and BIC values, we are left with conflicting conclusions. BIC would favor our first model with a natural spline on obesity. This model has the lowest number of parameters favoring its BIC score. In terms of MSE, it does not perform as well as model 2 which takes a natural spline of obesity and egg fat content. Out of the 6 models we tested (using a quasi-forward step selection method), model 2 returned the lowest MSE score. Since we are most concerned about prediction accuracy over parsimony (though model 2 is still quite parsimonious), our natural spline exercise point towards using a natural spline regression of two predictors: obesity and eggs with knot degrees of freedom of 4 for both. We ran a sanity check by creating a model with obesity (by far the best natural spline predictor) and another strong natural spline predictor (animal fats). This sanity check was to see if there were other possible and more optimal predictor interactions outside of our forward stepwise method. The MSE and BIC for that two predictor model was not as optimal as its forward stepwise counterpart model 2 with obesity and egg as predictors. Moving forward, we'll look into generalized additive methods. 

# GAM: Jon (Leave Descriptions Until Last, Just Write Code)
```{r}
library(gam)
```


GAM 1 CV 
```{r}
# Empty vector for CV preds
gam1_preds <- numeric(length(nutrition_cln$Deaths))

# CV loop
for (i in 1:length(folds)) {
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  
  # Define GAM
  gam1 <- gam(Deaths~ s(Eggs) + s(Obesity), data = nutrition_cln, subset = train_index)
  
  # Test set preds
  gam1_test_preds <- predict(gam1, newdata = nutrition_cln[test_index, ])
  gam1_preds[test_index] <- gam1_test_preds
}

# CV MSE
gam1_cv_mse <- mean((gam1_preds - nutrition_cln$Deaths)^2)
gam1_cv_mse

```


GAM 2 CV 
```{r}
# Empty vector for CV preds
gam2_preds <- numeric(length(nutrition_cln$Deaths))

# CV loop
for (i in 1:length(folds)) {
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  
  # Define GAM
  gam2 <- gam(Deaths~ s(Obesity) + poly(Eggs, 4), data = nutrition_cln, subset = train_index)
  
  # Test set preds
  gam2_test_preds <- predict(gam2, newdata = nutrition_cln[test_index, ])
  
  gam2_preds[test_index] <- gam2_test_preds
}

# CV MSE
gam2_cv_mse <- mean((gam2_preds - nutrition_cln$Deaths)^2)
gam2_cv_mse
```

GAM 3 CV
```{r}
# Empty vector for CV preds
gam3_preds <- numeric(length(nutrition_cln$Deaths))

# CV loop
for (i in 1:length(folds)) {
  train_index <- folds[[i]]
  test_index <- setdiff(1:length(nutrition_cln$Deaths), train_index)
  
  # Define GAM
  gam3 <- gam(Deaths~ poly(Eggs, 3) + Obesity, data = nutrition_cln, subset = train_index)
  
  # Test set preds
  gam3_test_preds <- predict(gam3, newdata = nutrition_cln[test_index, ])
  
  gam3_preds[test_index] <- gam3_test_preds
}

# CV MSE
gam3_cv_mse <- mean((gam3_preds - nutrition_cln$Deaths)^2)
gam3_cv_mse

```


